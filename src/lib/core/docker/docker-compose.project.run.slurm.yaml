
services:

  project-slurm:
    image: ${DN_PROJECT_HUB:?err}/${DN_PROJECT_IMAGE_NAME:?err}-slurm:${PROJECT_TAG:?err}
    environment:
      # SJOB_ID: ${SJOB_ID}
      DN_HOST: 'linux/x86'
      DN_CONTAINER_NAME: ${DN_CONTAINER_NAME:?err}-slurm${SJOB_ID}
      DN_ENTRYPOINT_TRACE_EXECUTION: false
      DN_PROJECT_USER: ${DN_PROJECT_USER:?err}
      DN_ACTIVATE_POWERLINE_PROMT: true
      IS_TEAMCITY_RUN: ${IS_TEAMCITY_RUN}
      IS_SLURM_RUN: ${IS_SLURM_RUN}
      # Use CUDA_VISIBLE_DEVICES instead of  NVIDIA_VISIBLE_DEVICES and NVIDIA_DRIVER_CAPABILITIES
      #  as the slurm server automatically assign gpu id per job
      CUDA_VISIBLE_DEVICES: ${CUDA_VISIBLE_DEVICES}
      DISPLAY: ${DISPLAY}
      QT_X11_NO_MITSHM: 1
      XAUTHORITY: /tmp/.docker.xauth
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - /tmp/.docker.xauth:/tmp/.docker.xauth:rw # Share system folder
      # ....Dockerized-NorLab-project internal. ...................................................
      - ${SUPER_PROJECT_ROOT:?err}/.dockerized_norlab_project/configuration/project_entrypoints/:/project_entrypoints/:ro
      - ${SUPER_PROJECT_ROOT}/.dockerized_norlab_project/dn_container_env_variable/:/dn_container_env_variable/:rw
      # ....Add host volume you want to mount into the container...................................
      - ${SUPER_PROJECT_ROOT}/:/ros2_ws/src/${DN_PROJECT_GIT_NAME:?err}/:rw
      - ${SUPER_PROJECT_ROOT}/artifact/:/ros2_ws/src/${DN_PROJECT_GIT_NAME:?err}/artifact/:rw
      - ${SUPER_PROJECT_ROOT}/external_data/:/ros2_ws/src/${DN_PROJECT_GIT_NAME:?err}/external_data/:ro
    env_file:
      - path: ${SUPER_PROJECT_ROOT:?err}/.dockerized_norlab_project/configuration/.env.dnp
        required: true
      - path: ${DNP_ROOT:?err}/src/lib/core/docker/.env.dnp-internal
        required: true
      - path: ${SUPER_PROJECT_ROOT}/.dockerized_norlab_project/configuration/.env
        required: true
      - path: ${SUPER_PROJECT_ROOT}/.dockerized_norlab_project/configuration/.env.local
        required: false
    tty: false
    stdin_open: false
    privileged: false # (Priority) ToDo: assessment (true or false)
    security_opt:
      - seccomp=unconfined
      - apparmor=unconfined
    cap_add:
      - SYS_PTRACE
      - SYS_NICE
    network_mode: host    # allow the container to have full access to the hostâ€™s networking system
    # ports:
    #   - "2222:2222" # ssh pycharm-debugger
    #   - "6006:6006" # tensorboard
    #   - "8888:8888" # optuna-dashboard
    pid: host
    ipc: host   # see comment  https://stable-baselines3.readthedocs.io/en/master/guide/install.html#run-the-images-cpu-gpu
    init: true  # Propagate exit code (See remark in task NMO-266)
    runtime: nvidia

  project-slurm-no-gpu:
    extends:
      service: project-slurm
    runtime: !reset []
