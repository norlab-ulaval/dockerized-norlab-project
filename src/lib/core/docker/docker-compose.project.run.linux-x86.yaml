services:

  #
  # Docker compose project run version for running on an x86 linux workstation
  # Requirements:
  #   1. Nvidia driver are installed. See https://www.nvidia.com/Download/index.aspx
  #   2. Install nvidia-container-toolkit.
  #       See https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
  #   3. Setup GPU access during build
  #       See https://saturncloud.io/blog/how-to-use-gpu-from-a-docker-container-a-guide-for-data-scientists-and-software-engineers
  #         at section "utilizing-a-gpu-during-docker-build"
  #       i.e. $ vim /etc/docker/daemon.json
  #             {
  #               "default-runtime": "nvidia",
  #               "runtimes": {
  #                 "nvidia": {
  #                   "path": "/usr/bin/nvidia-container-runtime",
  #                   "runtimeArgs": []
  #                 }
  #               }
  #             }
  #            $ systemctl restart docker
  #
  #        If you want to launch containers without accessing the NVIDIA runtime, you’ll have to specify it when running the
  #         container using the --runtime flag (for example: docker run --runtime=runc ...)
  #
  # Ref Nvidia container toolkit:
  #   - https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html
  #
  project-develop:
    entrypoint: [] # Overide project-develop entrypoint as it will be started by up_and_attach.bash
    image: ${DN_PROJECT_HUB:?err}/${DN_PROJECT_IMAGE_NAME:?err}-develop:${PROJECT_TAG:?err}
    container_name: ${DN_CONTAINER_NAME:?err}
    environment:
      DN_HOST: 'linux/x86'
      DN_ENTRYPOINT_TRACE_EXECUTION: false
      DN_CONTAINER_NAME: ${DN_CONTAINER_NAME}
      DN_ACTIVATE_POWERLINE_PROMT: true
      IS_TEAMCITY_RUN: ${IS_TEAMCITY_RUN}
      NVIDIA_VISIBLE_DEVICES: all   # substitute for `--gpus all` flag
      #     see https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html#environment-variables-oci-spec
      NVIDIA_DRIVER_CAPABILITIES: all
      #     see https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html#driver-capabilities
      DISPLAY: ${DISPLAY}
      QT_X11_NO_MITSHM: 1
      XAUTHORITY: /tmp/.docker.xauth
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - /tmp/.docker.xauth:/tmp/.docker.xauth:rw # Share system folder
      # ....Dockerized-NorLab-project internal. ...................................................
      - ${SUPER_PROJECT_ROOT:?err}/.dockerized_norlab_project/configuration/project_entrypoints/:/project_entrypoints/:ro
      - ${SUPER_PROJECT_ROOT}/.dockerized_norlab_project/dn_container_env_variable/:/dn_container_env_variable/:rw
      # ....Add host volume you want to mount into the container...................................
      - ${SUPER_PROJECT_ROOT}/:/ros2_ws/src/${DN_PROJECT_GIT_NAME:?err}/:rw
      - ${SUPER_PROJECT_ROOT}/artifact/:/ros2_ws/src/${DN_PROJECT_GIT_NAME:?err}/artifact/:rw
      - ${SUPER_PROJECT_ROOT}/external_data/:/ros2_ws/src/${DN_PROJECT_GIT_NAME:?err}/external_data/:ro
    env_file:
      - path: ${SUPER_PROJECT_ROOT:?err}/.dockerized_norlab_project/configuration/.env.dnp
        required: true
      - path: ${DNP_ROOT:?err}/src/lib/core/docker/.env.dnp-internal
        required: true
      - path: ${SUPER_PROJECT_ROOT}/.dockerized_norlab_project/configuration/.env
        required: true
      - path: ${SUPER_PROJECT_ROOT}/.dockerized_norlab_project/configuration/.env.local
        required: false
    tty: true
    stdin_open: true
    devices:
      - /dev/input/js0
      # ....From jetson-container run.sh...........................................................
      - /dev/snd
      - /dev/bus/usb
    privileged: true
    security_opt:
      - seccomp=unconfined
      - apparmor=unconfined
    cap_add:
      - SYS_PTRACE
      - SYS_NICE
    network_mode: host    # allow the container to have full access to the host’s networking system
    pid: host
    ipc: host   # see comment  https://stable-baselines3.readthedocs.io/en/master/guide/install.html#run-the-images-cpu-gpu
    init: true  # Propagate exit code (See remark in task NMO-266)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  project-deploy:
    extends:
      service: project-develop
    image: ${DN_PROJECT_HUB:?err}/${DN_PROJECT_IMAGE_NAME:?err}-deploy:${PROJECT_TAG:?err}
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - /tmp/.docker.xauth:/tmp/.docker.xauth:rw # Share system folder
      # ....Add host volume you want to mount into the container...................................
      - ${SUPER_PROJECT_ROOT:?err}/.dockerized_norlab_project/configuration/project_entrypoints/:/project_entrypoints/:ro
